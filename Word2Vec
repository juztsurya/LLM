from gensim.models import Word2Vec
import re
text = input("Enter a sentence: ") # Take input sentence
tokens = re.findall(r'\b\w+\b', text.lower()) # Tokenize sentence using regex
model = Word2Vec([tokens], vector_size=50, window=3, min_count=1, sg=1) # Train Word2Vec
# Display embeddings for each word
print("Word2Vec Embeddings:")
for word in tokens:
    print(word, "->", model.wv[word])
